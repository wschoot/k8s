---
- hosts: all
  become: true
  tasks:
    - name: Disable SELinux
      selinux:
        state: disabled

    - name: Enable password login
      lineinfile:
        dest: '/etc/ssh/sshd_config'
        regexp: "^#?PasswordAuthentication"
        line: "PasswordAuthentication yes"
      notify: restart sshd

    - name: Stop firewalld
      service:
        name: firewalld
        state: stopped

    - name: Add repository
      yum_repository:
        name: kubernetes
        description: Kubernetes
        baseurl: https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
        enabled: yes
        gpgcheck: yes
        repo_gpgcheck: yes
        gpgkey:
          - https://packages.cloud.google.com/yum/doc/yum-key.gpg
          - https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg

    - name: upgrade all packages
      yum:
        name: tmux
        state: latest
        update_cache: yes

    - name: Install alles wat met kube begint
      package:
        name: "{{ item }}"
        state: installed
      with_items:
        - kubelet
        - kubeadm
        - kubectl

    - name: Install docker
      package:
        name: '{{ item }}'
        state: installed
      with_items:
        - docker
        - etcd
        - vim
        - docker-distribution

    - name: Start kubelet
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      with_items:
        - kubelet
        - docker-distribution
        - docker

    - name: Disable swapoff
      command: swapoff -a

    - name: Disable swapoff permanently
      replace:
        path: /etc/fstab
        regexp: '^(\s*)([^#\n]+\s+)(\w+\s+)swap(\s+.*)$'
        replace: '#\1\2\3swap\4'
        backup: yes

    - name: sysctl
      sysctl:
        name: "{{ item }}"
        state: present
        value: "1"
        sysctl_file: /etc/sysctl.d/k8s.conf
        sysctl_set: yes
        reload: yes
      loop:
        - net.bridge.bridge-nf-call-ip6tables
        - net.bridge.bridge-nf-call-iptables

  handlers:
    - name: restart sshd
      service:
        name: sshd
        state: restarted

- hosts: master
  become: true
  environment:
    PATH: /usr/local/bin:{{ ansible_env.PATH }}
  vars:
    # https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network
    podnetwork: flannel
    istio: false
    apps: false
  vars_files:
    - "vars/{{ podnetwork }}.yml"

  tasks:
    - name: symlink bashhistory
      file:
        src: /vagrant/bash_history
        dest: /root/.bash_history
        state: link
      tags: symlink

    - name: Copy yaml files
      become: false
      copy:
        src: "{{ item }}"
        dest: "~/"
      with_fileglob:
        - files/*.yaml
        - files/istio-1.2.2/*.yaml

    - name: Configure .bashrc
      lineinfile:
        dest: /root/.bashrc
        line: "{{ item }}"
      with_items:
        - 'export KUBECONFIG=/etc/kubernetes/admin.conf'
        - 'source <(kubectl completion bash)'
        - 'alias k=kubectl'
        - 'complete -F __start_kubectl k'
        - 'export PATH=$PATH:/usr/local/bin/'

    #- name: kubeadm config pull
    #  command: kubeadm config images pull

    - name: kubeadm init
      command: >
        kubeadm init
        --pod-network-cidr {{ cidr }}
        --apiserver-advertise-address "{{ ansible_eth1.ipv4.address }}"
      args:
        creates: /etc/kubernetes/admin.conf

    - name: kubeversion (needed for weave)
      shell: |
        set -o pipefail
        kubectl version | base64 | tr -d '\n'
      register: kubeversion
      when: podnetwork == "weave"

    # https://docs.projectcalico.org/v3.8/getting-started/kubernetes/
    # https://github.com/projectcalico/calico/issues/1795
    - name: kube podnetwork
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply
        -f {{ podnetworkyaml }}

    - name: kube dashboard
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply
        -f
        https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml

    - name: kube clusteradmin
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        create clusterrolebinding
        --user system:serviceaccount:kube-system:default kube-system-cluster-admin
        --clusterrole cluster-admin

    - name: kube dashboardadmin
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        create clusterrolebinding kubernetes-dashboard
        --clusterrole=cluster-admin
        --serviceaccount=kube-system:kubernetes-dashboard

    - name: kube adminuser
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply
        -f ~vagrant/dashboard-adminuser.yaml

    - name: kube adminrole
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply
        -f ~vagrant/dashboard-adminrole.yaml

    - name: kube nginx run
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        create deployment nginx --image=nginx
      when: apps

    - name: kube nginx expose
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        expose deployment nginx --type=NodePort --name=nginx --port=81 --target-port=80
      when: apps

    # https://istio.io/docs/concepts/what-is-istio/
    # https://istio.io/docs/setup/kubernetes/install/kubernetes/
    - name: istio
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply -f {{ item }}
      loop:
        - ~vagrant/crd-10.yaml
        - ~vagrant/crd-11.yaml
        - ~vagrant/crd-12.yaml
        - ~vagrant/crd-certmanager-10.yaml
        - ~vagrant/crd-certmanager-11.yaml
        - ~vagrant/istio-demo.yaml
      when: istio

    # https://kubernetes.io/docs/tutorials/stateless-application/guestbook/
    - name: gastenboek
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply -f {{ item }}
      loop:
        - https://k8s.io/examples/application/guestbook/redis-master-deployment.yaml
        - https://k8s.io/examples/application/guestbook/redis-master-service.yaml
        - https://k8s.io/examples/application/guestbook/redis-slave-deployment.yaml
        - https://k8s.io/examples/application/guestbook/redis-slave-service.yaml
        - https://k8s.io/examples/application/guestbook/frontend-deployment.yaml
        - https://k8s.io/examples/application/guestbook/frontend-service.yaml
      when: apps

    - name: kube nginx patch
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        patch svc nginx -n default
        -p '{"spec": {"type": "LoadBalancer", "externalIPs":["{{ ansible_eth1.ipv4.address }}"], "ports":[{"port":81, "targetPort":80}]}}'
      when: apps

    - name: kube guestbook patch
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        patch svc frontend -n default
        -p '{"spec": {"type": "LoadBalancer", "externalIPs":["{{ ansible_eth1.ipv4.address }}"]}}'
      when: apps

    - name: Get join link
      command: kubeadm token create --print-join-command
      register: joinlink

    - name: Start proxy
      cron:
        name: "start proxy"
        special_time: "reboot"
        job: "tmux new-session -d -s proxy 'kubectl --kubeconfig=/etc/kubernetes/admin.conf proxy --accept-hosts='.*' --address {{ ansible_lo.ipv4.address }} |& tee ~/tmux.log '"

    # https://docs.ansible.com/ansible/latest/user_guide/playbooks_delegation.html
    - name: Join workers to master
      command: "{{ joinlink.stdout }}"
      delegate_to: "{{ item }}"
      with_items: "{{ groups['nodes'] }}"

    - name: start proxy
      shell: |
        set -o pipefail
        tmux new-session -d -s proxy "kubectl --kubeconfig=/etc/kubernetes/admin.conf proxy --accept-hosts='.*' --address {{ ansible_lo.ipv4.address }} |& tee ~/tmux.log "

    - name: Waits for port 6443
      wait_for:
        host: "{{ ansible_eth1.ipv4.address }}"
        port: 6443

    - name: kube adminuser
      shell: |
        set -o pipefail
        kubectl --kubeconfig=/etc/kubernetes/admin.conf describe sa admin-user -n kube-system | awk '/^Tokens/ { print $2 }'
      register: adminuser

    - name: download helm
      get_url:
        url: https://raw.githubusercontent.com/helm/helm/master/scripts/get
        dest: /opt/helm
        mode: '0400'

    - name: install helm
      command: bash /opt/helm

    - name: init helm
      command: /usr/local/bin/helm init
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      args:
        creates: /root/.helm

    #- name: Wait for tiller to settle
    #  shell: >
    #    kubectl --kubeconfig=/etc/kubernetes/admin.conf
    #    describe pods tiller-deploy --namespace kube-system | awk '/^Status/ { print $2}'
    #  register: cmd_res
    #  retries: 10
    #  delay: 6
    #  until: cmd_res.stdout == "Running"

    - name: even wachten..
      command: kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system wait --for=condition=Ready pod -l name=tiller --timeout=300s

    - name: install traefik
      command: |
        helm install stable/traefik
        --name traefik
        --set dashboard.enabled=true,serviceType=NodePort,dashboard.domain=dashboard.traefik,rbac.enabled=true
        --namespace kube-system
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf

    - name: installeer metallb
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply
        -f
        https://raw.githubusercontent.com/google/metallb/v0.8.1/manifests/metallb.yaml

    - name: kube traefik patch
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        patch svc traefik -n kube-system
        -p '{"spec": {"type": "LoadBalancer"}}'

    - name: traefik
      command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf
        apply -f {{ item }}
      loop:
        - ~vagrant/metallb-configmap.yaml
        - ~vagrant/kube-dashboard-via-traefik.yaml

    - name: kube token
      shell: |
        set -o pipefail
        kubectl --kubeconfig=/etc/kubernetes/admin.conf describe secret {{ adminuser.stdout }} -n kube-system | awk ' /^token/ { print $2 }'
      register: token

    - name: save token in file
      copy:
        content: "{{ token.stdout }}"
        dest: ~/token

    - name: show weblink
      debug:
        msg:
          - "Dashboard http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/"
          - "Token: {{ token.stdout }}"
#    - name: show var
#      debug:
#        var: "{{ item }}"
#      loop:
#        - token
#        - adminuser
#        - getnodes.stdout_lines
#      tags: show
    #- name: "Add K8S Token and Hash to dummy host"
    #  add_host:
    #    name:   "K8S_TOKEN_HOLDER"
    #    joinlink:  "{{ joinlink.stdout }}"
#
#- hosts: nodes
## SCope https://liquidat.wordpress.com/2017/09/13/howto-reference-ansible-variables-between-plays/
#  tasks:
#    - name: Get join link
#      command: "{{ hostvars['K8S_TOKEN_HOLDER']['joinlink'] }}"

# http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/
# Vraag je token op met :
# [root@master vagrant]# kubectl describe secret $(kubectl describe sa admin-user -n kube-system | awk '/^Tokens/ { print $2 }') -n kube-system | awk ' /^token/ { print $2 }'
